В общем случае — **нет**: детерминированный (не стохастический) градиентный спуск с фиксированным шагом **не имеет механизма “выпрыгивания” из локального минимума**, и потому **не гарантирует** выход из него.

### Почему локальный минимум “ловит” градиентный спуск
Итерация GD:
$$x_{k+1}=x_k-\alpha\nabla f(x_k).$$

Если $x^\*$ — **локальный минимум**, то $\nabla f(x^\*)=0$, значит:
$$x_{k+1}=x_k=x^\*,$$
то есть, **попав ровно в минимум, алгоритм остаётся там навсегда**.

Более того, если минимум **строгий** (например, $\nabla^2 f(x^\*)\succ 0$) и шаг $\alpha$ достаточно мал (типично условие вида $\alpha<\frac{2}{L}$ при $L$-липшицевом градиенте), то окрестность $x^\*$ является **областью притяжения**: начиная достаточно близко, GD **сойдётся к $x^\*$ и “не убежит”**.

### Можно ли “выйти” за счёт большого шага?
Технически, при **слишком большом** фиксированном $\alpha$ итерации могут:
- **перепрыгивать** через область минимума,
- начать **колебаться/разбегаться**,

и тем самым покинуть окрестность минимума. Но это уже не “осмысленное” *спусковое* поведение: обычно при таком $\alpha$ **не сохраняется убывание $f$**, и нет гарантий сходимости вообще. Поэтому это не считается надёжным способом “выхода из локальных минимумов”.

### Важное уточнение: седловые точки
GD может **уходить от седловых точек** даже без шума: многие седла являются неустойчивыми, и малое отклонение ведёт к уходу. Но это **не про локальные минимумы**.

**Итог:** фиксированный детерминированный GD **может застрять в локальном минимуме** и не имеет гарантии “побега”; “побег” возможен лишь ценой слишком большого шага и потери гарантий/стабильности.